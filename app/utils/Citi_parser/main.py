import time
import logging
import os
import json
import signal
import sys
from lxml import html
from dotenv import load_dotenv
from request_handler import request, ParserStoppedException, check_stop_flag
from queries import (url, PRODUCTS_QUERY, PRODUCT_VARIABLE)
from data_processors import product_answer, rating_answer, review_answer

load_dotenv()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
_parser_stopped = False

def signal_handler(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"""
    global _parser_stopped
    _parser_stopped = True
    logging.info("üõë –ü–û–õ–£–ß–ï–ù –°–ò–ì–ù–ê–õ –û–°–¢–ê–ù–û–í–ö–ò –í –ì–õ–ê–í–ù–û–ú –ü–†–û–¶–ï–°–°–ï!")
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª-—Ñ–ª–∞–≥ –¥–ª—è –¥–æ—á–µ—Ä–Ω–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    with open('STOP_PARSER.flag', 'w') as f:
        f.write('STOP')

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# –¢–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
category = os.getenv('CATEGORY')

# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('parser.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
def ensure_directory_exists(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)
        logging.info(f"–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
def fetch_products_for_category(category_name):
    global _parser_stopped
    logging.info(f"–ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_name}")

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category_dir = os.path.join('data', category_name)
    ensure_directory_exists(category_dir)
    
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è –¥–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    products_file = os.path.join(category_dir, '–¢–æ–≤–∞—Ä—ã.json')
    reviews_file = os.path.join(category_dir, '–û—Ç–∑—ã–≤—ã.json')
    articles_file = os.path.join(category_dir, '–û–±–∑–æ—Ä—ã.json')
    
    # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–¥–∏–º –∫–æ–ø–∏—é –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    ensure_directory_exists('data')

    # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
    for filename in [products_file, reviews_file, articles_file]:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('[\n')
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–µ—Ä–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    first_product = True
    first_rating = True
    first_review = True

    current_page_products = 1
    has_next_page_products = True
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    all_products = []

    try:
        while has_next_page_products and not _parser_stopped:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π
            check_stop_flag()
            
            logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–¥—É–∫—Ç–∞ ‚Ññ{current_page_products}")

            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ API
                product_request_data = request(url, PRODUCTS_QUERY, PRODUCT_VARIABLE(category_name, current_page_products), "–≤—Å–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π –≤ –æ—Ç–≤–µ—Ç–µ
                if not product_request_data:
                    logging.error(f"–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    break
                    
                if 'data' not in product_request_data:
                    logging.error(f"–ü–æ–ª–µ 'data' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ API –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {product_request_data}")
                    break
                    
                if 'productsFilter' not in product_request_data['data']:
                    logging.error(f"–ü–æ–ª–µ 'productsFilter' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ API –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ data: {product_request_data['data'].keys()}")
                    break
                    
                if 'record' not in product_request_data['data']['productsFilter']:
                    logging.error(f"–ü–æ–ª–µ 'record' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ productsFilter –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ productsFilter: {product_request_data['data']['productsFilter'].keys()}")
                    break
                    
                record = product_request_data['data']['productsFilter']['record']
                
                if 'pageInfo' not in record:
                    logging.error(f"–ü–æ–ª–µ 'pageInfo' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ record –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ record: {record.keys()}")
                    break
                    
                if 'hasNextPage' not in record['pageInfo']:
                    logging.error(f"–ü–æ–ª–µ 'hasNextPage' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ pageInfo –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ pageInfo: {record['pageInfo'].keys()}")
                    break
                    
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                has_next_page_products = record['pageInfo']['hasNextPage']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
                if 'products' not in record:
                    logging.error(f"–ü–æ–ª–µ 'products' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ record –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}")
                    logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ record: {record.keys()}")
                    break
                    
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–æ–¥—É–∫—Ç
                for product in record['products']:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –ø—Ä–æ–¥—É–∫—Ç–æ–º
                        check_stop_flag()
                        if _parser_stopped:
                            raise ParserStoppedException("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ —Ñ–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Å –º–∏–Ω–∏–º—É–º–æ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ)
                        first_product = product_answer(product, first_product, products_file, fetch_detailed_data=not _parser_stopped)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ —Å–ø–∏—Å–∫–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                        all_products.append(product)
                        
                        # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞
                        # first_rating = rating_answer(product['id'], first_rating, reviews_file)
                        # first_review = review_answer(product['id'], first_review, articles_file)
                        
                        logging.info(f"–ü—Ä–æ–¥—É–∫—Ç {int(product['id'])} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                        
                        # –£–º–µ–Ω—å—à–∏–ª–∏ –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞
                        if not _parser_stopped:
                            time.sleep(1)
                    except ParserStoppedException:
                        raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                    except Exception as product_error:
                        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–¥—É–∫—Ç–∞: {str(product_error)}")
                        logging.error(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–¥—É–∫—Ç–∞: {product}")
                        continue
            except ParserStoppedException:
                raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            except Exception as page_error:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page_products}: {str(page_error)}")
                break
                
            current_page_products += 1
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            if current_page_products > 10:
                logging.warning("–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (10). –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞.")
                break
                
    except ParserStoppedException:
        logging.info("üõë –ü–ê–†–°–ï–† –û–°–¢–ê–ù–û–í–õ–ï–ù –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ú!")
        logging.info(f"‚úÖ –ù–∞ –º–æ–º–µ–Ω—Ç –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –¥–∞–∂–µ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
        for filename in [products_file, reviews_file, articles_file]:
            try:
                with open(filename, 'a', encoding='utf-8') as f:
                    f.write('\n]')
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–æ–≤–∞—Ä—ã
        if all_products:
            try:
                with open(os.path.join(category_dir, '–¢–æ–≤–∞—Ä—ã.json'), 'w', encoding='utf-8') as f:
                    json.dump(all_products, f, ensure_ascii=False, indent=2)
                logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
        
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª-—Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        try:
            if os.path.exists('STOP_PARSER.flag'):
                os.remove('STOP_PARSER.flag')
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Ñ–ª–∞–≥–∞: {e}")
        
        return all_products

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for filename in [products_file, reviews_file, articles_file]:
        with open(filename, 'a', encoding='utf-8') as f:
            f.write('\n]')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
    if all_products:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        with open(os.path.join(category_dir, '–¢–æ–≤–∞—Ä—ã.json'), 'w', encoding='utf-8') as f:
            json.dump(all_products, f, ensure_ascii=False, indent=2)
        
        logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category_name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        logging.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {category_dir}")
        logging.info(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
    else:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category_name}")
        # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        with open(os.path.join(category_dir, '–¢–æ–≤–∞—Ä—ã.json'), 'w', encoding='utf-8') as f:
            json.dump([], f, ensure_ascii=False, indent=2)
    
    return all_products

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    global _parser_stopped
    
    if not category:
        logging.error("–û—à–∏–±–∫–∞: –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        products = fetch_products_for_category(category)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category_dir = os.path.join('data', category)
        ensure_directory_exists(category_dir)
        
        with open(os.path.join(category_dir, '–¢–æ–≤–∞—Ä—ã.json'), 'w', encoding='utf-8') as f:
            f.write('[\n')
            for i, product in enumerate(products):
                json_str = json.dumps(product, ensure_ascii=False)
                if i < len(products) - 1:
                    f.write(json_str + ',\n')
                else:
                    f.write(json_str + '\n')
            f.write(']')
        
        logging.info(f"–¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª '–¢–æ–≤–∞—Ä—ã.json' –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏")
        
    except ParserStoppedException:
        logging.info("üèÅ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù –ü–û –¢–†–ï–ë–û–í–ê–ù–ò–Æ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø")
        # –ü—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ 0 (—É—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ)
        return 0
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞: {e}")
        return 1
    finally:
        # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª-—Ñ–ª–∞–≥ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ
        try:
            if os.path.exists('STOP_PARSER.flag'):
                os.remove('STOP_PARSER.flag')
        except:
            pass

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code if exit_code is not None else 0)