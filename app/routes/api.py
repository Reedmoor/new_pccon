from flask import Blueprint, request, jsonify, render_template
from app import db
from app.utils.standardization.import_products import import_products
import json
import logging
import subprocess
import os
import sys
from datetime import datetime
from pathlib import Path
import requests
import threading

api_bp = Blueprint('api', __name__)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis/DB)
_notifications_lock = threading.Lock()
_notifications_storage = []

def add_notification(notification_data):
    """–î–æ–±–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    with _notifications_lock:
        _notifications_storage.append(notification_data)
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        if len(_notifications_storage) > 50:
            _notifications_storage.pop(0)

@api_bp.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–µ—Ä–≤–µ—Ä–æ–≤"""
    try:
        from app.models.models import UnifiedProduct
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        product_count = UnifiedProduct.query.count()
        
        return jsonify({
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'database': 'connected',
            'product_count': product_count,
            'server': 'pccon_web',
            'version': '1.0'
        }), 200
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return jsonify({
            'status': 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'server': 'pccon_web'
        }), 500

@api_bp.route('/upload-products', methods=['POST'])
def upload_products():
    """API endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({'error': 'Content-Type must be application/json'}), 400
        
        data = request.get_json()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        if not data or 'products' not in data:
            return jsonify({'error': 'Missing products data'}), 400
        
        products = data['products']
        if not isinstance(products, list):
            return jsonify({'error': 'Products must be a list'}), 400
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–≥—Ä—É–∑–∫–∏
        upload_type = data.get('upload_type', 'local_parser')
        source = data.get('source', 'unknown')
        
        logger.info(f"Received {len(products)} products from {source} (type: {upload_type})")
        
        # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ù–ï —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã –ª–æ–∫–∞–ª—å–Ω–æ
        if upload_type == 'server_sync':
            logger.info("Server sync detected - importing directly to database without saving files")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
            try:
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –Ω–∞–ø—Ä—è–º—É—é –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                from app.utils.standardization.import_products import import_products_from_data
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
                result = import_products_from_data(products, source=source)
                
                # –°–æ–∑–¥–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                sync_notification = {
                    'type': 'server_sync',
                    'source': source,
                    'products_count': len(products),
                    'timestamp': datetime.now().isoformat(),
                    'sync_id': data.get('sync_id', 'unknown'),
                    'status': 'success'
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                add_notification(sync_notification)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (–≤ –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —á–µ—Ä–µ–∑ WebSocket)
                logger.info(f"üì® SYNC NOTIFICATION: {sync_notification}")
                
                return jsonify({
                    'success': True,
                    'message': f'Successfully synced {len(products)} products from server',
                    'imported_count': len(products),
                    'upload_type': upload_type,
                    'source': source,
                    'notification': sync_notification,
                    'files_saved': False  # –§–∞–π–ª—ã –ù–ï —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                }), 200
                
            except Exception as import_error:
                logger.error(f"Error importing synced products: {import_error}")
                return jsonify({
                    'success': False,
                    'error': f'Server sync failed: {str(import_error)}',
                    'received_count': len(products),
                    'upload_type': upload_type
                }), 500
        
        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã –∫–∞–∫ –æ–±—ã—á–Ω–æ
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_filename = f"local_parser_data_{timestamp}.json"
            temp_path = f"data/{temp_filename}"
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs('data', exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –æ–∂–∏–¥–∞–µ—Ç import_products
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(products, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Saved products data to {temp_path}")
            
            # –°–æ–∑–¥–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ª–æ–∫–∞–ª—å–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ (–ù–ï –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ä–∞–∑—É)
            parse_notification = {
                'type': 'local_parsing',
                'source': source,
                'products_count': len(products),
                'timestamp': datetime.now().isoformat(),
                'filename': temp_filename,
                'status': 'saved',  # –ò–∑–º–µ–Ω–∏–ª–∏ —Å—Ç–∞—Ç—É—Å –Ω–∞ 'saved'
                'note': 'Data saved to file. Run import_products() to import into database.'
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            add_notification(parse_notification)
            
            logger.info(f"üì® PARSE NOTIFICATION: {parse_notification}")
            
            return jsonify({
                'success': True,
                'message': f'Successfully received and saved {len(products)} products to file. Use import_products() to import into database.',
                'received_count': len(products),
                'filename': temp_filename,
                'upload_type': upload_type,
                'notification': parse_notification,
                'files_saved': True,
                'imported_to_db': False  # –ù–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ –ë–î
            }), 200
    
    except Exception as e:
        logger.error(f"Error in upload_products endpoint: {e}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

@api_bp.route('/parser-status', methods=['GET'])
def parser_status():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ä—Å–µ—Ä–∞ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–≥—Ä—É–∑–æ–∫"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏
        import glob
        from datetime import datetime, timedelta
        
        # –ò—â–µ–º —Ñ–∞–π–ª—ã —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
        data_files = glob.glob('data/local_parser_data_*.json')
        data_files.sort(key=os.path.getmtime, reverse=True)
        
        recent_uploads = []
        for file_path in data_files[:10]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Ñ–∞–π–ª–æ–≤
            try:
                stat = os.stat(file_path)
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                upload_info = {
                    'filename': os.path.basename(file_path),
                    'upload_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'file_size': stat.st_size,
                    'product_count': len(data.get('products', [])) if isinstance(data, dict) else len(data)
                }
                recent_uploads.append(upload_info)
            except Exception as e:
                logger.error(f"Error reading file {file_path}: {e}")
        
        response_data = {
            'status': 'ok',
            'server_time': datetime.now().isoformat(),
            'recent_uploads': recent_uploads
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"Error getting parser status: {e}")
        return jsonify({'error': str(e)}), 500

@api_bp.route('/run-parser', methods=['POST'])
def run_parser():
    """–ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        mode = data.get('mode')
        if not mode:
            return jsonify({'error': 'Mode is required'}), 400
        
        # –ü—É—Ç—å –∫ –æ–±—ë—Ä—Ç–∫–µ old_dns_parser
        current_dir = Path(__file__).parent.parent.parent
        local_parser_dir = current_dir / 'local_parser'
        parser_script = local_parser_dir / 'dns_parser_wrapper.py'
        
        if not parser_script.exists():
            return jsonify({'error': 'DNS parser wrapper script not found'}), 404
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞
        cmd = [sys.executable, str(parser_script)]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
        show_browser = data.get('show_browser', True)
        logger.info(f"Show browser parameter: {show_browser}")
        
        # old_dns_parser –≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä, –ø–æ—ç—Ç–æ–º—É headless –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
        if not show_browser:
            logger.warning("Headless mode not supported with old_dns_parser - browser will be visible")
        
        if mode == 'test':
            cmd.append('--test-only')
        elif mode == 'single_product':
            # old_dns_parser –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
            return jsonify({'error': 'Single product parsing not supported with old DNS parser'}), 400
        elif mode == 'category':
            category = data.get('category')
            limit = data.get('limit', 5)
            if not category:
                return jsonify({'error': 'Category is required for category mode'}), 400
            cmd.extend(['--category', category, '--limit', str(limit)])
        else:
            return jsonify({'error': f'Unknown mode: {mode}'}), 400
        
        # –î–æ–±–∞–≤–ª—è–µ–º URL —Å–µ—Ä–≤–µ—Ä–∞
        cmd.extend(['--server-url', 'https://pcconf.ru'])
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        logger.info(f"Starting parser with command: {' '.join(cmd)}")
        
        # –î–ª—è –≤–∏–¥–∏–º–æ–≥–æ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º batch-—Ñ–∞–π–ª –Ω–∞ Windows
        if show_browser and mode != 'test':
            # –î–ª—è –≤–∏–¥–∏–º–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º batch-—Ñ–∞–π–ª
            import subprocess
            import os
            
            # –ü—É—Ç—å –∫ batch-—Ñ–∞–π–ª—É –¥–ª—è –≤–∏–¥–∏–º–æ–≥–æ —Ä–µ–∂–∏–º–∞
            batch_file = local_parser_dir / 'run_visible_parser.bat'
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è batch-—Ñ–∞–π–ª–∞ (–±–µ–∑ python –∏ –ø—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É)
            batch_args = []
            skip_next = False
            for i, arg in enumerate(cmd):
                if skip_next:
                    skip_next = False
                    continue
                if 'python' in arg.lower():
                    continue
                if 'dns_parser_wrapper.py' in arg:
                    continue
                batch_args.append(arg)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º batch-—Ñ–∞–π–ª –≤ –Ω–æ–≤–æ–º –æ–∫–Ω–µ
            batch_cmd = ['cmd', '/c', 'start', str(batch_file)] + batch_args
            logger.info(f"Running visible mode with batch command: {' '.join(batch_cmd)}")
            
            process = subprocess.Popen(
                batch_cmd,
                cwd=str(local_parser_dir),
                shell=True
            )
            
            # –î–ª—è batch-—Ñ–∞–π–ª–∞ –Ω–µ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π PID, –ø–æ—ç—Ç–æ–º—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö —Å—Ä–∞–∑—É
            return jsonify({
                'status': 'started',
                'message': 'Parser started in visible mode - new console window should open',
                'mode': mode,
                'command': ' '.join(batch_args),
                'note': 'Check for new console window with browser'
            })
        else:
            # –î–ª—è headless —Ä–µ–∂–∏–º–∞ –∏–ª–∏ —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—É—Å–∫
            process = subprocess.Popen(
                cmd,
                cwd=str(local_parser_dir),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # –î–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—É –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–ø—É—Å–∫
            import time
            time.sleep(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞
            poll = process.poll()
            if poll is None:
                # –ü—Ä–æ—Ü–µ—Å—Å –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è
                return jsonify({
                    'status': 'started',
                    'message': f'Parser started successfully with PID {process.pid}',
                    'mode': mode,
                    'command': ' '.join(cmd)
                })
            elif poll == 0:
                # –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞)
                stdout, stderr = process.communicate()
                return jsonify({
                    'status': 'completed',
                    'message': 'Parser completed successfully',
                    'output': stdout,
                    'mode': mode
                })
            else:
                # –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π
                stdout, stderr = process.communicate()
                return jsonify({
                    'status': 'error',
                    'message': f'Parser failed with exit code {poll}',
                    'error': stderr,
                    'output': stdout
                }), 500
        
    except Exception as e:
        logger.error(f"Error running parser: {e}")
        return jsonify({'error': str(e)}), 500

@api_bp.route('/test-visible-browser', methods=['POST'])
def test_visible_browser():
    """–¢–µ—Å—Ç–æ–≤—ã–π endpoint –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–∏–¥–∏–º–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞"""
    try:
        # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É —Å–∫—Ä–∏–ø—Ç—É
        current_dir = Path(__file__).parent.parent.parent
        local_parser_dir = current_dir / 'local_parser'
        test_script = local_parser_dir / 'test_web_browser.py'
        
        if not test_script.exists():
            return jsonify({'error': 'Test script not found'}), 404
        
        # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–¥–∏–º–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        cmd = [sys.executable, str(test_script), '--server-url', 'http://localhost:5001']
        
        logger.info(f"Starting visible browser test with command: {' '.join(cmd)}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
        import subprocess
        import os
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        env = os.environ.copy()
        
        process = subprocess.Popen(
            cmd,
            cwd=str(local_parser_dir),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            env=env
        )
        
        # –î–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—É –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—É—Å–∫
        import time
        time.sleep(2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
        poll = process.poll()
        if poll is None:
            return jsonify({
                'status': 'started',
                'message': 'Visible browser test started successfully',
                'pid': process.pid,
                'command': ' '.join(cmd)
            })
        else:
            stdout, stderr = process.communicate()
            return jsonify({
                'status': 'completed',
                'message': 'Browser test completed',
                'output': stdout,
                'error': stderr
            })
        
    except Exception as e:
        logger.error(f"Error starting visible browser test: {e}")
        return jsonify({'error': str(e)}), 500

@api_bp.route('/import-to-docker', methods=['POST'])
def import_to_docker():
    """–ò–º–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ Docker —Å–µ—Ä–≤–µ—Ä"""
    try:
        # –ü—É—Ç—å –∫ —Å–∫—Ä–∏–ø—Ç—É –∏–º–ø–æ—Ä—Ç–∞
        current_dir = Path(__file__).parent.parent.parent
        local_parser_dir = current_dir / 'local_parser'
        import_script = local_parser_dir / 'upload_existing_data.py'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞
        if not import_script.exists():
            return jsonify({'error': 'Import script not found'}), 404
        
        # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–º–ø–æ—Ä—Ç–∞
        cmd = [sys.executable, str(import_script), '--server-url', 'https://pcconf.ru']
        
        logger.info(f"Starting import with command: {' '.join(cmd)}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–º–ø–æ—Ä—Ç
        process = subprocess.Popen(
            cmd,
            cwd=str(local_parser_dir),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥)
        try:
            stdout, stderr = process.communicate(timeout=60)
            
            if process.returncode == 0:
                # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                lines = stdout.split('\n')
                imported_count = 0
                categories = []
                
                for line in lines:
                    # –ò—â–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                    if 'Total products uploaded:' in line:
                        try:
                            imported_count = int(line.split(':')[-1].strip().replace(',', ''))
                        except:
                            pass
                    # –ò—â–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    elif 'üìÇ Processing:' in line:
                        try:
                            category = line.split('üìÇ Processing:')[-1].strip()
                            if category and category not in categories:
                                categories.append(category)
                        except:
                            pass
                    # –¢–∞–∫–∂–µ –∏—â–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–≥—Ä—É–∑–∫–∏
                    elif 'Successfully uploaded' in line and 'products from' in line:
                        try:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è
                            parts = line.split('products from')
                            if len(parts) > 1:
                                category = parts[1].split('...')[0].strip()
                                if category and category not in categories:
                                    categories.append(category)
                        except:
                            pass
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ª–æ–≥–∞—Ö, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å–≤–æ–¥–∫–µ
                if imported_count == 0:
                    for line in lines:
                        if 'Success:' in line and 'files' in line:
                            try:
                                # –ò—â–µ–º —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ "Success: 10/10 files"
                                parts = line.split('/')
                                if len(parts) > 1:
                                    success_count = int(parts[0].split(':')[-1].strip())
                                    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ
                                    if success_count > 0 and imported_count == 0:
                                        imported_count = success_count * 30  # –ø—Ä–∏–º–µ—Ä–Ω–æ 30 —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                            except:
                                pass
                
                return jsonify({
                    'status': 'success',
                    'message': 'Data imported successfully to Docker server',
                    'imported_count': imported_count,
                    'categories': categories,
                    'success_files': len(categories),
                    'output': stdout
                })
            else:
                return jsonify({
                    'status': 'error',
                    'message': f'Import failed with exit code {process.returncode}',
                    'error': stderr,
                    'output': stdout
                }), 500
                
        except subprocess.TimeoutExpired:
            process.kill()
            return jsonify({
                'status': 'timeout',
                'message': 'Import process timed out (60 seconds)',
                'note': 'Large datasets may take longer. Check Docker server manually.'
            }), 408
        
    except Exception as e:
        logger.error(f"Error running import: {e}")
        return jsonify({'error': str(e)}), 500

@api_bp.route('/test-connection', methods=['GET'])
def test_connection():
    """–ü—Ä–æ—Å—Ç–æ–π endpoint –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    return jsonify({
        'status': 'ok',
        'message': 'Local parser API is working',
        'server_time': datetime.now().isoformat()
    }), 200

@api_bp.route('/local-data-manager', methods=['POST'])
def local_data_manager():
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        action = data.get('action')
        if not action:
            return jsonify({'error': 'Action is required'}), 400
        
        # –ü—É—Ç—å –∫ –º–µ–Ω–µ–¥–∂–µ—Ä—É –¥–∞–Ω–Ω—ã—Ö
        current_dir = Path(__file__).parent.parent.parent
        local_parser_dir = current_dir / 'local_parser'
        manager_script = local_parser_dir / 'local_data_manager.py'
        
        if not manager_script.exists():
            return jsonify({'error': 'Local data manager script not found'}), 404
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—É
        cmd = [sys.executable, str(manager_script), '--server-url', 'https://pcconf.ru']
        
        if action == 'stats':
            cmd.append('--stats')
        elif action == 'organize':
            cmd.append('--organize')
        elif action == 'upload':
            cmd.append('--upload')
        elif action == 'all':
            cmd.append('--all')
        else:
            return jsonify({'error': f'Unknown action: {action}'}), 400
        
        logger.info(f"Running local data manager with command: {' '.join(cmd)}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
        process = subprocess.Popen(
            cmd,
            cwd=str(local_parser_dir),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥)
        try:
            stdout, stderr = process.communicate(timeout=60)
            
            if process.returncode == 0:
                # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                lines = stdout.split('\n')
                stats = {}
                categories = []
                
                for line in lines:
                    if 'Raw data files:' in line:
                        try:
                            stats['raw_files'] = int(line.split(':')[-1].strip())
                        except:
                            pass
                    elif 'Organized files:' in line:
                        try:
                            stats['organized_files'] = int(line.split(':')[-1].strip())
                        except:
                            pass
                    elif 'Total products:' in line:
                        try:
                            total_str = line.split(':')[-1].strip().replace(',', '')
                            stats['total_products'] = int(total_str)
                        except:
                            pass
                    elif line.strip().startswith('‚úÖ Organized:'):
                        try:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ñ–∞–π–ª–µ
                            parts = line.split('->')
                            if len(parts) > 1:
                                new_filename = parts[1].strip()
                                categories.append(new_filename)
                        except:
                            pass
                
                return jsonify({
                    'status': 'success',
                    'message': f'Local data manager completed successfully ({action})',
                    'action': action,
                    'stats': stats,
                    'categories': categories,
                    'output': stdout
                })
            else:
                return jsonify({
                    'status': 'error',
                    'message': f'Local data manager failed with exit code {process.returncode}',
                    'error': stderr,
                    'output': stdout
                }), 500
                
        except subprocess.TimeoutExpired:
            process.kill()
            return jsonify({
                'status': 'timeout',
                'message': 'Local data manager timed out (60 seconds)',
                'note': 'Operation may still be running in background.'
            }), 408
        
    except Exception as e:
        logger.error(f"Error running local data manager: {e}")
        return jsonify({'error': str(e)}), 500

@api_bp.route('/export-products', methods=['GET'])
def export_products():
    """–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å–µ—Ä–≤–µ—Ä–∞–º–∏"""
    try:
        from app.models.models import UnifiedProduct
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        limit = request.args.get('limit', type=int)
        category = request.args.get('category', type=str)
        
        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = UnifiedProduct.query
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É –ø—Ä–æ–¥—É–∫—Ç–∞ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
        if category:
            query = query.filter_by(product_type=category)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
        if limit:
            query = query.limit(limit)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã
        products = query.all()
        
        logger.info(f"Exporting {len(products)} products for server synchronization")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π
        exported_products = []
        for product in products:
            product_data = {
                'id': product.id,
                'name': product.product_name,
                'price_discounted': float(product.price_discounted) if product.price_discounted else None,
                'price_original': float(product.price_original) if product.price_original else None,
                'vendor': product.vendor,
                'url': product.product_url,
                'availability': product.availability,
                'product_type': product.product_type,
                'images': product.get_images(),
                'characteristics': product.get_characteristics(),
                'rating': product.rating,
                'number_of_reviews': product.number_of_reviews
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ —á—Ç–æ –æ–∂–∏–¥–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
            categories = []
            if product.product_type:
                categories.append({
                    'name': product.product_type.replace('_', ' ').title(),
                    'url': f'/products/{product.product_type}'
                })
            
            product_data['categories'] = categories
            
            # –î–æ–±–∞–≤–ª—è–µ–º brand_name –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            characteristics = product.get_characteristics()
            if characteristics and 'brand' in characteristics:
                product_data['brand_name'] = characteristics['brand']
            
            exported_products.append(product_data)
        
        return jsonify({
            'success': True,
            'products': exported_products,
            'total_count': len(exported_products),
            'export_time': datetime.now().isoformat(),
            'filters': {
                'category': category,
                'limit': limit
            }
        }), 200
        
    except Exception as e:
        logger.error(f"Error exporting products: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to export products: {str(e)}'
        }), 500

@api_bp.route('/products', methods=['GET'])
def get_products():
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–∞–ª–∏–∞—Å –¥–ª—è export-products)"""
    return export_products()

@api_bp.route('/export-and-send-to-docker', methods=['POST'])
def export_and_send_to_docker():
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑—ã –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ Docker —Å–µ—Ä–≤–µ—Ä"""
    try:
        from app.models.models import UnifiedProduct
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑—ã
        products = UnifiedProduct.query.all()
        
        if not products:
            return jsonify({
                'success': False,
                'error': 'No products found in local database'
            }), 404
        
        logger.info(f"Exporting {len(products)} products to send to Docker server")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        exported_products = []
        for product in products:
            product_data = {
                'id': product.id,
                'name': product.product_name,
                'price_discounted': float(product.price_discounted) if product.price_discounted else None,
                'price_original': float(product.price_original) if product.price_original else None,
                'vendor': product.vendor,
                'url': product.product_url,
                'availability': product.availability,
                'product_type': product.product_type,
                'images': product.get_images(),
                'characteristics': product.get_characteristics(),
                'rating': product.rating,
                'number_of_reviews': product.number_of_reviews
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            categories = []
            if product.product_type:
                categories.append({
                    'name': product.product_type.replace('_', ' ').title(),
                    'url': f'/products/{product.product_type}'
                })
            
            product_data['categories'] = categories
            
            # –î–æ–±–∞–≤–ª—è–µ–º brand_name –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            characteristics = product.get_characteristics()
            if characteristics and 'brand' in characteristics:
                product_data['brand_name'] = characteristics['brand']
            
            exported_products.append(product_data)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º payload –¥–ª—è Docker —Å–µ—Ä–≤–µ—Ä–∞
        current_time = datetime.now()
        payload = {
            'products': exported_products,
            'source': 'local_export_to_docker',
            'upload_type': 'manual_export',
            'timestamp': current_time.isoformat(),
            'export_id': f'export_{current_time.timestamp()}',
            'total_products': len(exported_products)
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ Docker —Å–µ—Ä–≤–µ—Ä
        docker_url = 'https://pcconf.ru'
        try:
            response = requests.post(
                f"{docker_url}/api/upload-products",
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"Successfully sent {len(exported_products)} products to Docker server")
                
                return jsonify({
                    'success': True,
                    'sent_count': len(exported_products),
                    'docker_server': docker_url,
                    'message': 'Products successfully sent to Docker server',
                    'docker_response': result
                }), 200
            else:
                logger.error(f"Docker server returned status {response.status_code}: {response.text}")
                return jsonify({
                    'success': False,
                    'error': f'Docker server error: {response.status_code} - {response.text}'
                }), 500
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to connect to Docker server: {e}")
            return jsonify({
                'success': False,
                'error': f'Cannot connect to Docker server: {str(e)}'
            }), 500
        
    except Exception as e:
        logger.error(f"Error in export_and_send_to_docker: {e}")
        return jsonify({
            'success': False,
            'error': f'Export error: {str(e)}'
        }), 500

@api_bp.route('/check-docker-status', methods=['GET'])
def check_docker_status():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Docker —Å–µ—Ä–≤–µ—Ä–∞"""
    try:
        import requests
        
        docker_url = 'https://pcconf.ru'
        
        try:
            response = requests.get(f"{docker_url}/health", timeout=10)
            
            if response.status_code == 200:
                return jsonify({
                    'docker_available': True,
                    'docker_url': docker_url,
                    'status': 'online',
                    'response_time': response.elapsed.total_seconds()
                }), 200
            else:
                return jsonify({
                    'docker_available': False,
                    'docker_url': docker_url,
                    'status': f'HTTP {response.status_code}',
                    'error': 'Docker server returned non-200 status'
                }), 200
                
        except requests.exceptions.RequestException as e:
            return jsonify({
                'docker_available': False,
                'docker_url': docker_url,
                'status': 'offline',
                'error': f'Connection failed: {str(e)}'
            }), 200
        
    except Exception as e:
        logger.error(f"Error checking Docker status: {e}")
        return jsonify({
            'docker_available': False,
            'error': f'Status check error: {str(e)}'
        }), 500

@api_bp.route('/import-notifications', methods=['GET'])
def get_import_notifications():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –∏–º–ø–æ—Ä—Ç–µ"""
    try:
        with _notifications_lock:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            recent_notifications = list(reversed(_notifications_storage[-20:]))
        
        return jsonify({
            'success': True,
            'notifications': recent_notifications,
            'total_count': len(_notifications_storage)
        }), 200
        
    except Exception as e:
        logger.error(f"Error getting notifications: {e}")
        return jsonify({
            'success': False,
            'error': f'Notifications error: {str(e)}',
            'notifications': []
        }), 500 