#!/usr/bin/env python3
"""
–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è old_dns_parser —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
"""

import os
import sys
import json
import logging
import requests
import time
import argparse
from pathlib import Path
from datetime import datetime, timedelta
import shutil

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('dns_wrapper')

class DNSParserWrapper:
    def __init__(self, server_url="https://pcconf.ru", visible_browser=True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ë—Ä—Ç–∫–∏ –¥–ª—è old_dns_parser
        
        Args:
            server_url: URL —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
            visible_browser: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –±—Ä–∞—É–∑–µ—Ä (True) –∏–ª–∏ headless —Ä–µ–∂–∏–º (False)
        """
        self.server_url = server_url.rstrip('/')
        self.visible_browser = visible_browser
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º old_dns_parser
        self.project_root = Path(__file__).parent.parent
        self.old_parser_dir = self.project_root / 'app' / 'utils' / 'old_dns_parser'
        self.parser_script = self.old_parser_dir / 'main.py'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        if not self.parser_script.exists():
            raise FileNotFoundError(f"Old DNS parser script not found: {self.parser_script}")
        
        self.log_messages = []
        self.session_start = datetime.now()
        
        print(f"üîß DNS Parser Wrapper initialized")
        print(f"   Server URL: {self.server_url}")
        print(f"   Browser mode: {'Visible' if self.visible_browser else 'Headless'}")
        print(f"   Parser script: {self.parser_script}")
        
    def test_server_connection(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–µ—Ä–æ–º"""
        try:
            logger.info(f"Testing connection to server: {self.server_url}")
            response = self.session.get(f"{self.server_url}/api/test-connection", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"‚úÖ Server connection successful: {data.get('message')}")
                return True
            else:
                logger.error(f"‚ùå Server returned status {response.status_code}")
                return False
                
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Failed to connect to server: {e}")
            return False
    
    def prepare_categories(self, category_name=None):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        categories_file = self.old_parser_dir / "categories.json"
        backup_file = self.old_parser_dir / "categories_backup.json"
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ backup –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if backup_file.exists():
            logger.info("Restoring categories from backup")
            shutil.copy(backup_file, categories_file)
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è, —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        if category_name:
            logger.info(f"Filtering categories for: {category_name}")
            try:
                with open(categories_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                filtered_data = []
                for item in data:
                    if 'categories' in item:
                        filtered_categories = {}
                        for cat_name, cat_data in item['categories'].items():
                            if category_name.lower() in cat_name.lower():
                                filtered_categories[cat_name] = cat_data
                        
                        if filtered_categories:
                            filtered_data.append({'categories': filtered_categories})
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                with open(categories_file, 'w', encoding='utf-8') as f:
                    json.dump(filtered_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"Categories filtered: {len(filtered_data)} items")
                
            except Exception as e:
                logger.error(f"Error filtering categories: {e}")
                return False
        
        return True
    
    def run_old_parser(self, category_name=None, limit=5):
        """–ó–∞–ø—É—Å–∫ old_dns_parser"""
        logger.info(f"Starting old DNS parser...")
        logger.info(f"Category: {category_name or 'all'}")
        logger.info(f"Limit: {limit}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if not self.prepare_categories(category_name):
            return False
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é old_dns_parser
        original_cwd = os.getcwd()
        try:
            os.chdir(self.old_parser_dir)
            logger.info(f"Changed directory to: {self.old_parser_dir}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –≤ sys.path
            if str(self.old_parser_dir) not in sys.path:
                sys.path.insert(0, str(self.old_parser_dir))
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º main
            try:
                import main
                logger.info("üöÄ Starting old_dns_parser main function...")
                logger.info("üéØ Browser window should open and show DNS-shop parsing process!")
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
                product_urls = main.main(
                    category_name=category_name,
                    limit_per_category=limit
                )
                
                logger.info(f"‚úÖ Old parser completed. Found {len(product_urls) if product_urls else 0} URLs")
                return True
                
            except Exception as e:
                logger.error(f"‚ùå Error running old parser: {e}")
                import traceback
                traceback.print_exc()
                return False
            
        finally:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –∏—Å—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            os.chdir(original_cwd)
    
    def send_results_to_server(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Å–µ—Ä–≤–µ—Ä"""
        product_data_file = self.old_parser_dir / "product_data.json"
        
        if not product_data_file.exists():
            logger.warning("No product_data.json found")
            return False
        
        try:
            with open(product_data_file, 'r', encoding='utf-8') as f:
                all_products = json.load(f)
            
            if not all_products:
                logger.warning("No products in product_data.json")
                return False
            
            # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã (–¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∏–Ω—É—Ç)
            recent_products = []
            cutoff_time = datetime.now() - timedelta(minutes=5)
            
            for product in all_products:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–µ last_updated, –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è
                if 'last_updated' in product:
                    try:
                        product_time = datetime.fromisoformat(product['last_updated'].replace('Z', '+00:00'))
                        if product_time.replace(tzinfo=None) > cutoff_time:
                            recent_products.append(product)
                    except:
                        continue
                # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏, —Ç–æ —Å—á–∏—Ç–∞–µ–º —Ç–æ–≤–∞—Ä –Ω–æ–≤—ã–º (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                elif len(recent_products) < 10:  # –ú–∞–∫—Å–∏–º—É–º 10 —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏
                    recent_products.append(product)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–¥–∞–≤–Ω–∏–µ —Ç–æ–≤–∞—Ä—ã, –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ
            if not recent_products:
                logger.info("No recent products found by timestamp, taking last 5 products")
                recent_products = all_products[-5:] if len(all_products) >= 5 else all_products
            
            logger.info(f"Sending {len(recent_products)} NEW products to server (out of {len(all_products)} total)...")
            
            payload = {
                'products': recent_products,
                'source': 'old_dns_parser_new',
                'total_in_file': len(all_products),
                'new_products_count': len(recent_products),
                'timestamp': datetime.now().isoformat(),
                'parser_version': '2.0'
            }
            
            response = self.session.post(
                f"{self.server_url}/api/upload-products",
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"‚úÖ Successfully sent {len(recent_products)} NEW products to server: {result.get('message')}")
                return True
            else:
                logger.error(f"‚ùå Server returned status {response.status_code}: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Failed to send data to server: {e}")
            return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='DNS Parser Wrapper')
    parser.add_argument('--category', type=str, help='Category name to parse (e.g., videokarty)')
    parser.add_argument('--limit', type=int, default=5, help='Number of products to parse per category')
    parser.add_argument('--server-url', type=str, default='https://pcconf.ru', help='Server URL')
    parser.add_argument('--test-only', action='store_true', help='Only test server connection')
    parser.add_argument('--product-url', type=str, help='Parse single product by URL (not supported in old parser)')
    
    args = parser.parse_args()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ë—Ä—Ç–∫–∏
    wrapper = DNSParserWrapper(server_url=args.server_url)
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Å–µ—Ä–≤–µ—Ä–æ–º
        if not wrapper.test_server_connection():
            logger.error("Cannot connect to server. Please check server is running.")
            return 1
        
        if args.test_only:
            logger.info("‚úÖ Connection test completed successfully")
            return 0
        
        if args.product_url:
            logger.error("Single product parsing not supported with old parser")
            return 1
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º old_dns_parser
        logger.info("üéØ Starting DNS parsing with VISIBLE browser!")
        if wrapper.run_old_parser(args.category, args.limit):
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä
            if wrapper.send_results_to_server():
                logger.info("‚úÖ Parsing completed successfully!")
                return 0
            else:
                logger.error("‚ùå Failed to send results to server")
                return 1
        else:
            logger.error("‚ùå Parsing failed")
            return 1
    
    except KeyboardInterrupt:
        logger.info("Parsing interrupted by user")
        return 1
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        return 1

if __name__ == '__main__':
    sys.exit(main()) 